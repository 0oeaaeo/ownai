# Hugging Face Inference Endpoints

With [Hugging Face Inference Endpoints](https://huggingface.co/inference-endpoints), easily deploy your models on dedicated, fully managed infrastructure. Keep your costs low with their secure, compliant and flexible production solution.

## Set up

To use these AIs, you should set the environment variable `HUGGINGFACEHUB_API_TOKEN` (e.g. in your server's `.env` file).
Then download the aifile and load it with ownAI (in ownAI, click on the logo in the upper left corner to open the menu, then select "AI Workshop", then "New AI" and "Load Aifile").

## Privacy

Your models are running on an external provider's infrastructure. Please refer to the provider's privacy policy for details.
